train:
  algorithm: 'SVTR'
  local_rank: 0
  data_root_train: /code/wujilong/data/scene #/src/notebooks/MyWorkData/train_data/data   ## lmdb数据的根目录
  train_lmdb_file: ['scene_train'] #训练集lmdb名称地址和data_root一起使用
  data_root_val: /code/wujilong/data/scene
  val_lmdb_file: ['scene_val','scene_test'] #验证集lmdb名称地址和data_root一起使用
  isVal: True
  val_step: 20000
  key_file: /code/wujilong/code/OCR-TextRecog/keyFile/chn_all.txt # key文件地址
  num_workers: 16 ## dataload的worker数
  fixKeyON: False  ## 是否需要对key进行清洗，去除一些无用字符
  fixKeytype: 'En'
  use_tia: False ## 是否需要用tia 数据增强
  ConAug: True
  usel2loss: False
  aug_prob: 0.4 ## 图片做数据增强的概率
  imgH: 32   ## 图片的H，只能为32
  imgW: 256  ## 图片的W，建议280，320
  isGray: False ##是否用灰度图训练
  alphabet: '' ## 训练用的key，这里默认即可，代码会根据key_file数据更改
  nclass: 1000 ## 字符类别，这里默认即可，代码会根据key_file数据更改
  epochs: 100 ## 训练的epoch数
  warmepochs: 1 ## warm训练的epoch数
  batch_size: 128 ## 训练的batch_size
  show_iter: 5000 ## 迭代多少次显示一次loss
  save_dir: '/code/wujilong/model/checkpointFile2'  ## 模型和log保存的地址
  restore: False ## 是否开启断点继续训练
  resume_file: './checkpointFile/modelFile/SVTR-epoch-2-wordAcc-0.0000-ID.pth' ### 断点继续训练所需加载的模型地址

model:
  backbone_function: models.backbones.svtrNet,SVTRNet
  head_function: models.heads.svtrHead,svtrHead
#   optim_function: models.optimizer.optimizer,AdamDecay
  optim_function: models.optimizer.optimizer,AdamWDecay
  backbone:
    img_size: [32,256]
    in_channels: 3
    embed_dim: [64, 128, 256]
    depth: [3, 6, 3]
    num_heads: [2, 4, 8]
    mixer: "['Local']*6+['Global']*6"
    local_mixer: [[7, 11], [7, 11], [7, 11]]
    patch_merging: 'Conv'
    out_channels: 192
    out_char_num: 40
    last_stage: True
    sub_num: 2
    prenorm: False
    use_lenhead: False
    mid_channels: None # True
    return_feats: False
  STN:
    STN_ON: True
    use_rep: False
    tps_inputsize: [32, 64]
    tps_outputsize: [32, 256]
    num_control_points: 20
    tps_margins: [0.05, 0.05]
    stn_activation: 'relu'
    stn_lr: 0.001
  
optimizer:
  optim_type: 'cos'
  base_lr: 0.002
  min_lr: 0.000001
  momentum: 0.9
  weight_decay: 0.05
  beta1: 0.9
  beta2: 0.99
  eps: 8.e-8
  alpha: 0 
  amsgrad: False
  gama: 0.1
  schedule: [8,15,18]
  no_weight_decay_param:
    is_ON: True
    param_names: ['pos_embed','norm']
    weight_decay: 0.01
  
  
infer:
 model_file: './checkpointFile/modelFile/SVTR-step-10000-wordAcc-0.5132-chinese.pth'
