train:
  algorithm: 'SVTR' 
  data_root_train: /src/notebooks/MyWorkData/exprimentRecData/train #/src/notebooks/MyWorkData/train_data/data   ## lmdb数据的根目录
  train_lmdb_file: ['MJSynth','SynthText'] #训练集lmdb名称地址和data_root一起使用
  data_root_val: /src/notebooks/MyWorkData/exprimentRecData/evaluation
  val_lmdb_file: ['CUTE80','IC03_860','IC03_867','IC13_1015','IC13_857','IC15_1811','IC15_2077','IIIT5k_3000','SVT','SVTP'] #验证集lmdb名称地址和data_root一起使用
  isVal: True
  key_file: /src/notebooks/MyWorkData/exprimentRecData/train/key.txt  # key文件地址
  num_workers: 6 ## dataload的worker数
  fixKeyON: True  ## 是否需要对key进行清洗，去除一些无用字符
  fixKeytype: 'En'
  use_tia: True ## 是否需要用tia 数据增强
  usel2loss: False
  aug_prob: 0.4 ## 图片做数据增强的概率
  imgH: 48   ## 图片的H，只能为32
  imgW: 256  ## 图片的W，建议280，320
  isGray: False ##是否用灰度图训练
  alphabet: '' ## 训练用的key，这里默认即可，代码会根据key_file数据更改
  nclass: 1000 ## 字符类别，这里默认即可，代码会根据key_file数据更改
  epochs: 20 ## 训练的epoch数
  warmepochs: 2 ## warm训练的epoch数
  batch_size: 512 ## 训练的batch_size
  show_iter: 50 ## 迭代多少次显示一次loss
  save_dir: './checkpointFile'  ## 模型和log保存的地址
  restore: True ## 是否开启断点继续训练
  resume_file: './checkpointFile/modelFile/SVTR-epoch-2-wordAcc-0.0000-ID.pth' ### 断点继续训练所需加载的模型地址

model:
  backbone_function: models.backbones.svtrNet,SVTRNet
  head_function: models.heads.svtrHead,svtrHead
#   optim_function: models.optimizer.optimizer,AdamDecay
  optim_function: models.optimizer.optimizer,AdamWDecay
  backbone:
    img_size: [32, 100]
    in_channels: 3
    embed_dim: [64, 128, 256]
    depth: [3, 6, 3]
    num_heads: [2, 4, 8]
    mixer: "['Local']*6+['Global']*6"
    local_mixer: [[7, 11], [7, 11], [7, 11]]
    patch_merging: 'Conv'
    out_channels: 192
    out_char_num: 25
    last_stage: True
    sub_num: 2
    prenorm: False
    use_lenhead: False
    mid_channels: None # True
    return_feats: False
  STN:
    STN_ON: True
    tps_inputsize: [32, 64]
    tps_outputsize: [32, 100]
    num_control_points: 20
    tps_margins: [0.05, 0.05]
    stn_activation: None
    stn_lr: 0.0005

# optimizer:
#   optim_type: 'cos'
#   base_lr: 0.0005
#   min_lr: 0.000001
#   momentum: 0.9
#   weight_decay: 0.005
#   beta1: 0.9
#   beta2: 0.99
#   gama: 0.1
#   schedule: [8,15,18]
  
optimizer:
  optim_type: 'cos'
  base_lr: 0.0005
  min_lr: 0.000001
  momentum: 0.9
  weight_decay: 0.05
  beta1: 0.9
  beta2: 0.99
  eps: 8.e-8
  alpha: 0 
  amsgrad: False
  gama: 0.1
  schedule: [8,15,18]
  no_weight_decay_param:
    ON: True
    param_names: ['pos_embed','norm']
    weight_decay: 0.
  
  
infer:
 model_file: './checkpointFile/modelFile/SVTR-epoch-2-wordAcc-0.0000-ID.pth'
